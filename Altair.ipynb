{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from datetime import datetime\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_dataset = pd.read_csv('C:\\\\Users\\\\JP\\\\Desktop\\\\Mohit\\\\Dataset\\\\Boonsong Dataset.csv')\n",
    "sortdata_csv = pd.read_csv('C:\\\\Users\\\\JP\\\\Desktop\\\\Mohit\\\\Dataset\\\\sorted_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_years = []\n",
    "\n",
    "for date in df_raw_dataset[\"sample date\"].unique():\n",
    "    date_obj = datetime.datetime.strptime(date, '%d-%b-%y')\n",
    "    year = date_obj.year\n",
    "    if year not in sorted_years:\n",
    "        sorted_years.append(year)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding 1 - Missing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert sample date to datetime format\n",
    "df_raw_dataset['sample date'] = pd.to_datetime(df_raw_dataset['sample date'])\n",
    "\n",
    "# Create a new column with the year of the sample date\n",
    "df_raw_dataset['year'] = df_raw_dataset['sample date'].dt.year\n",
    "\n",
    "# Aggregate by location, measure, and year to count the frequency of each combination\n",
    "freq = df_raw_dataset.groupby(['location', 'measure', 'year']).size().reset_index(name='frequency')\n",
    "\n",
    "list_location = freq['location'].unique().tolist()\n",
    "list_measure = freq['measure'].unique().tolist()\n",
    "\n",
    "for location in list_location:\n",
    "    for measure in list_measure:\n",
    "       result = freq.query('measure == \"{measure}\"')\n",
    "\n",
    "freq_measures = df_raw_dataset.groupby(['measure', 'year']).size().reset_index(name='frequency')\n",
    "\n",
    "for measure in list_measure:\n",
    "    result = freq_measures.query(f'measure== \"{measure}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_measures = df_raw_dataset.groupby(['measure','location', 'year']).size().reset_index(name='frequency')\n",
    "\n",
    "for measure in list_measure:\n",
    "    result = freq_measures.query(f'measure == \"{measure}\"')\n",
    "    year_diffs = result['year'].diff()\n",
    "    gaps = result[(year_diffs != 1)]\n",
    "    \n",
    "    if not gaps.empty:\n",
    "        result2 = freq_measures.query(f'measure== \"{measure}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_measures = df_raw_dataset.groupby(['measure','location', 'year']).size().reset_index(name='frequency')\n",
    "measure_freq_inconsistent = []\n",
    "\n",
    "for measure in list_measure:\n",
    "    result = freq_measures.query(f'measure == \"{measure}\"')\n",
    "    year_diffs = result['year'].diff()\n",
    "    gaps = result[(year_diffs != 1) & (~year_diffs.isna())]\n",
    "\n",
    "    if not gaps.empty:\n",
    "        measure_freq_inconsistent.append(measure)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart Finding 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_freq_inconsistent = []\n",
    "plots = []\n",
    "\n",
    "for location in list_location:\n",
    "    for measure in list_measure:\n",
    "        result = freq_measures.query(f'measure == \"{measure}\" and location==\"{location}\"')\n",
    "        year_diffs = result['year'].diff()\n",
    "        gaps = result[(year_diffs != 1) & (~year_diffs.isna())]\n",
    "\n",
    "        if not gaps.empty:\n",
    "            measure_freq_inconsistent.append(measure)\n",
    "        \n",
    "            # create a chart for the current measure\n",
    "            chart = alt.Chart(result).mark_bar().encode(\n",
    "                x='year:Q',\n",
    "                y='frequency:Q'\n",
    "            ).properties(\n",
    "                title=f'{measure} at {location} has gaps in between years:',\n",
    "                width=350,\n",
    "                height=200\n",
    "            )\n",
    "        \n",
    "            # add bars for gap years\n",
    "            gap_years = list(gaps['year'].unique())\n",
    "            gap_data = {'year': gap_years, 'frequency': [result[result['year'] == y]['frequency'].iloc[0] for y in gap_years]}\n",
    "            gap_chart = alt.Chart(pd.DataFrame(gap_data)).mark_bar().encode(\n",
    "                x='year:Q',\n",
    "                y='frequency:Q'\n",
    "            )\n",
    "        \n",
    "            chart += gap_chart\n",
    "            plots.append(chart)\n",
    "    print(len)\n",
    "    \n",
    "# concatenate all the plots in a grid\n",
    "grid = alt.vconcat(*[alt.hconcat(*plots[i:i+7]) for i in range(0, len(plots), 7)])\n",
    "\n",
    "# show the grid\n",
    "grid.configure_axis(\n",
    "    labelFontSize=8,\n",
    "    titleFontSize=6,\n",
    ").configure_title(\n",
    "    fontSize=10\n",
    ").configure_legend(\n",
    "    titleFontSize=12,\n",
    "    labelFontSize=8,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding 2 - change in collection frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert sample date to datetime format\n",
    "df_raw_dataset['sample date'] = pd.to_datetime(df_raw_dataset['sample date'])\n",
    "df_raw_dataset['year'] = df_raw_dataset['sample date'].dt.year\n",
    "freq = df_raw_dataset.groupby(['location', 'measure', 'year']).size().reset_index(name='frequency')\n",
    "\n",
    "list_location = freq['location'].unique().tolist()\n",
    "list_measure = freq['measure'].unique().tolist()\n",
    "\n",
    "for location in list_location:\n",
    "    for measure in list_measure:\n",
    "       result = freq.query('measure == \"{measure}\"')\n",
    "    \n",
    "freq_measures = df_raw_dataset.groupby(['location','measure', 'year']).size().reset_index(name='frequency')\n",
    "\n",
    "# create a list of plots\n",
    "plots = []\n",
    "df_missing_year=pd.DataFrame()\n",
    "\n",
    "for location in list_location:\n",
    "    for measure in list_measure:\n",
    "        result = freq_measures.query(f'location == \"{location}\" and measure == \"{measure}\"')\n",
    "        year_diffs = result['year'].diff()\n",
    "        gaps = result[(year_diffs != 1) & (~year_diffs.isna())]\n",
    "\n",
    "        if not gaps.empty:\n",
    "            new_row = {'location': location, 'measure': measure}\n",
    "            new_df = pd.DataFrame(new_row, index=[0])\n",
    "            df_missing_year=pd.concat([df_missing_year, new_df], ignore_index=True)\n",
    "\n",
    "\n",
    "#create a new dataframe with locations and mesaure with missing gaps\n",
    "\n",
    "merged_df = pd.merge(freq_measures, df_missing_year, on=['location', 'measure'], how='outer', indicator=True)\n",
    "\n",
    "df_freq_distribution = merged_df[merged_df['_merge'] == 'left_only'].drop('_merge', axis=1)\n",
    "\n",
    "df_freq_distribution = df_freq_distribution.groupby(['location', 'measure']).filter(lambda x: len(x) > 1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chart Finding 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "list_location_freq = df_freq_distribution['location'].unique().tolist()\n",
    "list_measure_freq = df_freq_distribution['measure'].unique().tolist()\n",
    "\n",
    "for location in list_location_freq:\n",
    "    for measure in list_measure_freq:\n",
    "        result = df_freq_distribution.query(f'location == \"{location}\" and measure == \"{measure}\"')\n",
    "        \n",
    "        if not result.empty:\n",
    "            chart = alt.Chart(result).mark_bar().encode(\n",
    "                x='year:O',\n",
    "                y='frequency:Q'\n",
    "            ).properties(\n",
    "                title=f'{measure} in {location}:'\n",
    "                \n",
    "            )\n",
    "            plots.append(chart)\n",
    "    \n",
    "grid = alt.vconcat(*[alt.hconcat(*plots[i:i+10]) for i in range(0, len(plots), 10)])\n",
    "\n",
    "# show the grid\n",
    "grid.configure_axis(\n",
    "    labelFontSize=10,\n",
    "    titleFontSize=9,\n",
    ").configure_title(\n",
    "    fontSize=5\n",
    ").configure_legend(\n",
    "    titleFontSize=9,\n",
    "    labelFontSize=5,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding 3 - Unrealistic Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_all=[]\n",
    "for measure in ['Copper','Fecal coliforms','Iron','Manganese','Total coliforms']:\n",
    "    # Filter the data for the current measure\n",
    "    filtered_data = df_raw_dataset[df_raw_dataset[\"measure\"] == measure]\n",
    "    # Create a bar chart for the current measure using Altair\n",
    "    chart = alt.Chart(filtered_data).mark_point().encode(\n",
    "        x=alt.X(\"year(sample date):O\", title=\"Years\", scale=alt.Scale(domain=[1998,1999,2000,2001,2002,2003,2004,\n",
    "                                                                              2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016])),\n",
    "        y=alt.Y(\"value:Q\", title=\"Value\"),\n",
    "        color='location',\n",
    "        tooltip=[\"measure\", \"value\", \"id\",\"location\",\"sample date:T\"]\n",
    "    ).properties(\n",
    "        title=f\"{measure} Measurement\",\n",
    "        width=600,\n",
    "        height=400\n",
    "    )\n",
    "    chart\n",
    "    chart_all.append((chart))\n",
    "\n",
    "    # Combine charts horizontally\n",
    "combined_chart = alt.hconcat(*chart_all)\n",
    "    # Display chart\n",
    "combined_chart.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Describe trends and anomalies with respect to chemical contamination"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Trends: changes over time and/or sensor site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "measurements = ['Potassium', 'Sulphates', 'Chemical Oxygen Demand (Cr)']\n",
    "charts_list = []\n",
    "    # Loop through measurements\n",
    "for measure in measurements:\n",
    "        # Filter data by measurement and location\n",
    "        df_filtered = df_raw_dataset[(df_raw_dataset['measure'] == measure) & (df_raw_dataset['location'].isin(['Kohsoom', 'Boonsri']))]\n",
    "        # Create base chart\n",
    "        base = alt.Chart(df_filtered, title=measure).encode(\n",
    "            x=alt.X('sample date:T', title='Year'),\n",
    "            y=alt.Y('value:Q', title=measure),\n",
    "            tooltip=['measure','location']\n",
    "        )\n",
    "        # Create selection \n",
    "        selection = alt.selection_single(\n",
    "            fields=['location'],\n",
    "            clear=False,\n",
    "            on='mouseover'\n",
    "        )\n",
    "\n",
    "        # Create chart with points colored by location\n",
    "        points = base.mark_point(filled=True, size=50).encode(\n",
    "            color=alt.condition(selection, 'location:N', alt.value('lightgray'), legend=None)\n",
    "        ).add_selection(selection)\n",
    "\n",
    "        # Create chart with lines colored by location\n",
    "        lines = base.mark_line().encode(\n",
    "            color=alt.Color('location:N', legend=None)\n",
    "        ).transform_filter(\n",
    "            selection\n",
    "        )\n",
    "        legend = alt.Chart(df_filtered).mark_point().encode(\n",
    "        alt.Y('location:N').axis(orient='right'),\n",
    "        color='location').add_params(\n",
    "        selection\n",
    "        )\n",
    "        # Combine points and lines charts\n",
    "        chart = alt.layer(points, lines).properties(width=300, height=200) \n",
    "        # Add chart to list\n",
    "        charts_list.append((chart|legend))\n",
    "    # Combine charts horizontally\n",
    "combined_chart = alt.hconcat(*charts_list)\n",
    "    # Display chart\n",
    "combined_chart.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Anomalies: sudden change over time or one site significantly different from others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brush = alt.selection_interval()\n",
    "\n",
    "base_chart = alt.Chart(sortdata_csv).mark_line().encode(\n",
    "    x='location:N',\n",
    "    y=alt.Y('sum(measure):Q', axis=alt.Axis(title='Sum of Value')),\n",
    "    \n",
    ")\n",
    "\n",
    "missing_year = []\n",
    "for measure in sortdata_csv[\"measure\"].unique():\n",
    "    selected_measure = sortdata_csv[sortdata_csv[\"measure\"] == measure]\n",
    "    \n",
    "    #Convert to year\n",
    "    for date in selected_measure[\"sample date\"].unique():\n",
    "        date_obj = datetime.datetime.strptime(date, '%d-%b-%y')\n",
    "        year = date_obj.year\n",
    "        \n",
    "        if year not in missing_year:\n",
    "         missing_year.append(year)\n",
    "\n",
    "    if len(missing_year) == len(sorted_years):\n",
    "        # Create chart\n",
    "        chart1 = alt.Chart(selected_measure).mark_circle().encode(\n",
    "        x=alt.X(\"location\"),\n",
    "        y=alt.Y(\"measure\"),\n",
    "        tooltip=[\"measure\", \"value\", \"id\",\"location\"],\n",
    "        size='average(value)', \n",
    "        color=alt.condition(brush, 'average(value):Q', alt.value('lightgray'))\n",
    "        ).properties(\n",
    "            title=f\"{measure} Measurement\",\n",
    "            width=400,\n",
    "            height=200\n",
    "        ).add_selection(\n",
    "        brush )\n",
    "        \n",
    "        chart2 = base_chart.encode(\n",
    "        y=alt.Y('average(value):Q', axis=alt.Axis(title='Sum of {}'.format(measure))),\n",
    "        color=alt.condition(brush, alt.value('lightgreen'), alt.value('lightgray'))\n",
    "        ).transform_filter(\n",
    "        alt.FieldOneOfPredicate(field='measure', oneOf=[measure])\n",
    "        ).properties(\n",
    "            title=f\"{measure} Measurement\",\n",
    "            width=400,\n",
    "            height=200\n",
    "        ).add_selection(\n",
    "        brush )\n",
    "        display(chart1 | chart2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
